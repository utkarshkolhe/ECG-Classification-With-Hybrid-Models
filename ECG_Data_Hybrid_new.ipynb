{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lcp1TSlrKNpA",
        "outputId": "6a42849d-a11d-4f5f-9e1e-82f94c54b98b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "7cL4znvhLKVS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df=pd.read_csv('/content/gdrive/MyDrive/ECGData/mitbih_train.csv',header=None)\n",
        "test_df=pd.read_csv('/content/gdrive/MyDrive/ECGData/mitbih_test.csv',header=None)"
      ],
      "metadata": {
        "id": "viu3wXknKzVj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[187]=train_df[187].astype(int)\n",
        "distribution=train_df[187].value_counts()\n",
        "print(distribution)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tLXYuI2LFFy",
        "outputId": "2f47d515-e9e9-4ed1-bdc2-fde3a787c676"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    72471\n",
            "4     6431\n",
            "2     5788\n",
            "1     2223\n",
            "3      641\n",
            "Name: 187, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df[187]=test_df[187].astype(int)\n",
        "distribution=test_df[187].value_counts()\n",
        "print(distribution)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58LryzyRM3L6",
        "outputId": "018a8139-c0fa-4541-e23f-96134d719830"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    18118\n",
            "4     1608\n",
            "2     1448\n",
            "1      556\n",
            "3      162\n",
            "Name: 187, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(distribution)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1DiWcrcLeJ8",
        "outputId": "09abf42f-25ab-487f-baae-0f72789c4d6a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "count1=10000\n",
        "newtraindf=(train_df[train_df[187]==0]).sample(n=count1)\n",
        "for i in range(1,5):\n",
        "  df_i=train_df[train_df[187]==i]\n",
        "  df_x=resample(df_i,replace=True,n_samples=count1)\n",
        "  newtraindf=pd.concat([newtraindf,df_x])\n",
        "\n",
        "newtestdf=pd.DataFrame()\n",
        "newvaldf=pd.DataFrame()\n",
        "\n",
        "for i in range(0,5):\n",
        "  shuffled_df=test_df[test_df[187]==i].sample(frac=1, random_state=42)\n",
        "  split_index = len(shuffled_df) // 2\n",
        "  df_half1 = shuffled_df.iloc[:split_index, :]\n",
        "  df_half2 = shuffled_df.iloc[split_index:, :]\n",
        "  newtestdf=pd.concat([newtestdf,df_half1])\n",
        "  newvaldf=pd.concat([newvaldf,df_half1])\n"
      ],
      "metadata": {
        "id": "YmtXwrjNLk2I"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def standardize(train,test,final_test):\n",
        "\n",
        "    mean = np.mean(train, axis=0)\n",
        "    std = np.std(train, axis=0)+0.000001\n",
        "\n",
        "    X_train = (train - mean) / std\n",
        "    X_test = (test-mean)/std\n",
        "    X_final_test = (final_test-mean)/std\n",
        "    return X_train,X_test,X_final_test"
      ],
      "metadata": {
        "id": "67wN-BhLQZXG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Access the datasets in the HDF5 file\n",
        "train_1_data = newtraindf[newtraindf.columns[:187]].values\n",
        "train_1_labels = newtraindf[newtraindf.columns[187:188]].values\n",
        "y_train = train_1_labels.reshape(train_1_labels.shape[0])\n",
        "train_1_data = train_1_data.reshape((train_1_data.shape[0],1,train_1_data.shape[1]))\n",
        "train_1_data = train_1_data.astype(float)\n",
        "\n",
        "\n",
        "test_1_data = newvaldf[newvaldf.columns[:187]].values\n",
        "test_1_labels = newvaldf[newvaldf.columns[187:188]].values\n",
        "y_test = test_1_labels.reshape(test_1_labels.shape[0])\n",
        "test_1_data = test_1_data.reshape((test_1_data.shape[0],1,test_1_data.shape[1]))\n",
        "test_1_data = test_1_data.astype(float)\n",
        "\n",
        "\n",
        "final_test_1_data = newtestdf[newtestdf.columns[:187]].values\n",
        "final_test_1_labels = newtestdf[newtestdf.columns[187:188]].values\n",
        "y_final_test = final_test_1_labels.reshape(final_test_1_labels.shape[0])\n",
        "final_test_1_data = final_test_1_data.reshape((final_test_1_data.shape[0],1,final_test_1_data.shape[1]))\n",
        "final_test_1_data = final_test_1_data.astype(float)\n",
        "\n",
        "X_train,X_test,X_final_test=standardize(train_1_data,test_1_data,final_test_1_data)"
      ],
      "metadata": {
        "id": "xP49goYBPOGY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98wlc3JCY0YW",
        "outputId": "991b4da6-35cf-47e0-f821-337a17ffcde8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 1, 187)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTSjAHBdY2w1",
        "outputId": "7da0c46c-91cc-45bd-940f-0fcb3f1d2200"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000,)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "L2mv8PrRSrL8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the NumPy arrays to PyTorch tensors\n",
        "train_loaded_data = torch.from_numpy(X_train)\n",
        "train_loaded_labels = torch.from_numpy(y_train)\n",
        "\n",
        "test_loaded_data = torch.from_numpy(X_test)\n",
        "test_loaded_labels = torch.from_numpy(y_test)\n",
        "\n",
        "final_test_loaded_data = torch.from_numpy(X_final_test)\n",
        "final_test_loaded_labels = torch.from_numpy(y_final_test)"
      ],
      "metadata": {
        "id": "0Z-yh2NIQ484"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import Module\n",
        "from torch.nn import Conv2d\n",
        "from torch.nn import Linear\n",
        "from torch.nn import MaxPool2d\n",
        "from torch.nn import ReLU\n",
        "from torch.nn import LogSoftmax\n",
        "from torch import flatten\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "eR6oLmzhS0QY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4AXl_QZS7Jk",
        "outputId": "f1f59fa1-df7c-4076-caae-a1a761db6b7f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 1, 187)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Define the CNN model\n",
        "class HybridCNN(nn.Module):\n",
        "  def __init__(self, num_classes=5):\n",
        "      super(HybridCNN, self).__init__()\n",
        "\n",
        "      self.hidden_size = 64\n",
        "      self.num_layers = 2\n",
        "\n",
        "      # Convolutional layers\n",
        "      self.conv1 = nn.Conv1d(1, 100, kernel_size=3, stride=1, padding=1)\n",
        "      self.relu1 = nn.ReLU()\n",
        "      self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "\n",
        "      self.conv2 = nn.Conv1d(100, 500, kernel_size=3, stride=1, padding=1)\n",
        "      self.relu2 = nn.ReLU()\n",
        "      self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "\n",
        "      self.conv3 = nn.Conv1d(500, 500, kernel_size=3, stride=1, padding=1)\n",
        "      self.relu3 = nn.ReLU()\n",
        "      self.pool3 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "\n",
        "\n",
        "      self.lstm = nn.LSTM(11500, self.hidden_size, self.num_layers, batch_first=True)\n",
        "\n",
        "      self.fc = nn.Linear(64, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = self.pool1(self.relu1(self.conv1(x)))\n",
        "      x = self.pool2(self.relu2(self.conv2(x)))\n",
        "      x = self.pool3(self.relu3(self.conv3(x)))\n",
        "      x = x.view(-1,1, 11500)  # Reshape before fully connected layer\n",
        "\n",
        "      h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "      c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "\n",
        "      out, _ = self.lstm(x, (h0, c0))\n",
        "      out = out[:, -1, :]\n",
        "      out = self.fc(out)\n",
        "      return out"
      ],
      "metadata": {
        "id": "LSKt6IOOSwuy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "8GsPplQbT5Rd"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 500  # Adjust as needed\n",
        "train_dataset = TensorDataset(train_loaded_data, train_loaded_labels)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_dataset = TensorDataset(test_loaded_data, test_loaded_labels)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "final_test_dataset = TensorDataset(final_test_loaded_data, final_test_loaded_labels)\n",
        "final_test_loader = DataLoader(final_test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "-xSLdfldUjiI"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getAccuracy(neuralmodel,loader):\n",
        "    neuralmodel.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs = inputs.float()\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = neuralmodel(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Calculate test accuracy\n",
        "    test_accuracy = correct / total\n",
        "    return test_accuracy,(f'{test_accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "L_cLjWWtUmGL"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo\n",
        "from torchinfo import summary\n",
        "cnn_model = HybridCNN()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "cnn_model.to(device)\n",
        "summary(cnn_model,(1,187))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GwXdEIfSWz_",
        "outputId": "f59a58f2-1bfb-458b-ac5d-027cd49c18f0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.8.0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "HybridCNN                                [1, 5]                    --\n",
              "├─Conv1d: 1-1                            [100, 187]                400\n",
              "├─ReLU: 1-2                              [100, 187]                --\n",
              "├─MaxPool1d: 1-3                         [100, 93]                 --\n",
              "├─Conv1d: 1-4                            [500, 93]                 150,500\n",
              "├─ReLU: 1-5                              [500, 93]                 --\n",
              "├─MaxPool1d: 1-6                         [500, 46]                 --\n",
              "├─Conv1d: 1-7                            [500, 46]                 750,500\n",
              "├─ReLU: 1-8                              [500, 46]                 --\n",
              "├─MaxPool1d: 1-9                         [500, 23]                 --\n",
              "├─LSTM: 1-10                             [1, 1, 64]                2,994,176\n",
              "├─Linear: 1-11                           [1, 5]                    325\n",
              "==========================================================================================\n",
              "Total params: 3,895,901\n",
              "Trainable params: 3,895,901\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 453.53\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.71\n",
              "Params size (MB): 15.58\n",
              "Estimated Total Size (MB): 16.29\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plotdata=[]\n",
        "num_epochs = 101\n",
        "cnn_model = HybridCNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "learning_rate = 0.01\n",
        "# cnn_model.train()\n",
        "# optimizer = optim.SGD(cnn_model.parameters(),lr=10)\n",
        "optimizer = optim.SGD(cnn_model.parameters(), lr=learning_rate,momentum=0.9)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "cnn_model.to(device)\n",
        "for epoch in range(num_epochs):\n",
        "    for inputs, labels in train_loader:\n",
        "        # print(inputs.shape)\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        inputs = inputs.float()\n",
        "        outputs = cnn_model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "    if (epoch) % 10 == 0:\n",
        "        # print(outputs.sum())\n",
        "        # print(loss.numpy())\n",
        "\n",
        "\n",
        "        train_val,trainacc=getAccuracy(cnn_model,train_loader)\n",
        "        test_val,testacc=getAccuracy(cnn_model,test_loader)\n",
        "        plotdata.append([epoch+1,train_val,test_val])\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "        print(\"Train Acc \",trainacc,\" Test Acc \",testacc)\n",
        "\n",
        "        cnn_model.train()\n",
        "print(\"Training complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZBO_uqZUrqJ",
        "outputId": "18e3fae2-dc93-4c11-f04c-edeee5b71632"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/101], Loss: 1.3791\n",
            "Train Acc  57.62%  Test Acc  27.43%\n",
            "Epoch [11/101], Loss: 0.1464\n",
            "Train Acc  95.62%  Test Acc  89.79%\n",
            "Epoch [21/101], Loss: 0.0521\n",
            "Train Acc  98.73%  Test Acc  93.28%\n",
            "Epoch [31/101], Loss: 0.0273\n",
            "Train Acc  99.42%  Test Acc  95.79%\n",
            "Epoch [41/101], Loss: 0.0137\n",
            "Train Acc  99.87%  Test Acc  96.18%\n",
            "Epoch [51/101], Loss: 0.0046\n",
            "Train Acc  99.92%  Test Acc  96.17%\n",
            "Epoch [61/101], Loss: 0.0059\n",
            "Train Acc  99.84%  Test Acc  95.68%\n",
            "Epoch [71/101], Loss: 0.0027\n",
            "Train Acc  99.98%  Test Acc  96.07%\n",
            "Epoch [81/101], Loss: 0.0011\n",
            "Train Acc  99.99%  Test Acc  96.14%\n",
            "Epoch [91/101], Loss: 0.0026\n",
            "Train Acc  99.87%  Test Acc  96.38%\n",
            "Epoch [101/101], Loss: 0.0012\n",
            "Train Acc  100.00%  Test Acc  96.35%\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plotdf = pd.DataFrame(columns=[\"Epoch\",\"Train Acc\",\"Test Acc\"])\n",
        "\n",
        "for dat in plotdata:\n",
        "  plotdf.loc[plotdf.shape[0]]=dat"
      ],
      "metadata": {
        "id": "JOfATjZkUvLC"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plotdf.to_csv(\"/content/gdrive/MyDrive/ECGData/PlotData/hybrid_plotdata.csv\",index=False)"
      ],
      "metadata": {
        "id": "Htk2HvMn80tY"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(cnn_model.state_dict(), \"/content/gdrive/MyDrive/ECGData/Models/HYBRID_model.pth\")"
      ],
      "metadata": {
        "id": "wrx0S3vW83xb"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = torch.load( \"/content/gdrive/MyDrive/ECGData/Models/HYBRID_model.pth\")"
      ],
      "metadata": {
        "id": "nAihnnPGPbhs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "total_labels=[]\n",
        "total_predicted=[]\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in final_test_loader:\n",
        "        inputs = inputs.float()\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = cnn_model(inputs)\n",
        "        total_labels = total_labels +labels.tolist()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        total_predicted = total_predicted+predicted.tolist()\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "# Calculate test accuracy\n",
        "test_accuracy = correct / total\n",
        "print(f'{test_accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "svBHcwN_87mV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39b3a519-eca8-4aaa-8ebf-f3c37d870492"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "96.35%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
      ],
      "metadata": {
        "id": "Z9gwmm4p89g1"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true_np = np.array(total_labels)\n",
        "y_pred_np = np.array(total_predicted)\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(y_true_np, y_pred_np, average='weighted')\n",
        "recall = recall_score(y_true_np, y_pred_np, average='weighted')\n",
        "f1 = f1_score(y_true_np, y_pred_np, average='weighted')\n",
        "accuracy = accuracy_score(y_true_np, y_pred_np)\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "SnkyQJTu8-8t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6758fb0-3397-4da9-95cf-e95f1aca6dcb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.9693109717367459\n",
            "Recall: 0.9635483281564041\n",
            "F1 Score: 0.9655741811950059\n",
            "Accuracy: 0.9635483281564041\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_df = pd.DataFrame(columns=[\"Metric\",\"Value\"])\n",
        "metrics_df.loc[0]=[\"Accuracy\",accuracy]\n",
        "metrics_df.loc[1]=[\"Precision\",precision]\n",
        "metrics_df.loc[2]=[\"Recall\",recall]\n",
        "metrics_df.loc[3]=[\"F1 Score\",f1]\n",
        "metrics_df.to_csv(\"/content/gdrive/MyDrive/ECGData/Metrics/HYBRID_metrics.csv\",index=False)"
      ],
      "metadata": {
        "id": "UCU5hGN88_gs"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vcXld0p18_jt"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9S_koF2d8_mO"
      },
      "execution_count": 28,
      "outputs": []
    }
  ]
}