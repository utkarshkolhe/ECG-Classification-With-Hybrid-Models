{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bnu4I_7AquB",
        "outputId": "6f4d08a4-c78e-4f66-b320-01d9cb46f344"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "7cL4znvhLKVS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df=pd.read_csv('/content/gdrive/MyDrive/ECGData/mitbih_train.csv',header=None)\n",
        "test_df=pd.read_csv('/content/gdrive/MyDrive/ECGData/mitbih_test.csv',header=None)"
      ],
      "metadata": {
        "id": "viu3wXknKzVj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[187]=train_df[187].astype(int)\n",
        "distribution=train_df[187].value_counts()\n",
        "print(distribution)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tLXYuI2LFFy",
        "outputId": "c2efa314-5fff-4eca-92fd-d5932fae1896"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    72471\n",
            "4     6431\n",
            "2     5788\n",
            "1     2223\n",
            "3      641\n",
            "Name: 187, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df[187]=test_df[187].astype(int)\n",
        "distribution=test_df[187].value_counts()\n",
        "print(distribution)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58LryzyRM3L6",
        "outputId": "f29c4de2-4997-4bb0-df14-02f630718bf2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    18118\n",
            "4     1608\n",
            "2     1448\n",
            "1      556\n",
            "3      162\n",
            "Name: 187, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(distribution)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1DiWcrcLeJ8",
        "outputId": "14f869c3-f796-4da6-ddda-baad4c9c6119"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "count1=10000\n",
        "newtraindf=(train_df[train_df[187]==0]).sample(n=count1)\n",
        "for i in range(1,5):\n",
        "  df_i=train_df[train_df[187]==i]\n",
        "  df_x=resample(df_i,replace=True,n_samples=count1)\n",
        "  newtraindf=pd.concat([newtraindf,df_x])\n",
        "\n",
        "newtestdf=pd.DataFrame()\n",
        "newvaldf=pd.DataFrame()\n",
        "\n",
        "for i in range(0,5):\n",
        "  shuffled_df=test_df[test_df[187]==i].sample(frac=1, random_state=42)\n",
        "  split_index = len(shuffled_df) // 2\n",
        "  df_half1 = shuffled_df.iloc[:split_index, :]\n",
        "  df_half2 = shuffled_df.iloc[split_index:, :]\n",
        "  newtestdf=pd.concat([newtestdf,df_half1])\n",
        "  newvaldf=pd.concat([newvaldf,df_half1])\n"
      ],
      "metadata": {
        "id": "YmtXwrjNLk2I"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def standardize(train,test,final_test):\n",
        "\n",
        "    mean = np.mean(train, axis=0)\n",
        "    std = np.std(train, axis=0)+0.000001\n",
        "\n",
        "    X_train = (train - mean) / std\n",
        "    X_test = (test-mean)/std\n",
        "    X_final_test = (final_test-mean)/std\n",
        "    return X_train,X_test,X_final_test"
      ],
      "metadata": {
        "id": "67wN-BhLQZXG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Access the datasets in the HDF5 file\n",
        "train_1_data = newtraindf[newtraindf.columns[:187]].values\n",
        "train_1_labels = newtraindf[newtraindf.columns[187:188]].values\n",
        "y_train = train_1_labels.reshape(train_1_labels.shape[0])\n",
        "train_1_data = train_1_data.reshape((train_1_data.shape[0],1,train_1_data.shape[1]))\n",
        "train_1_data = train_1_data.astype(float)\n",
        "\n",
        "\n",
        "test_1_data = newvaldf[newvaldf.columns[:187]].values\n",
        "test_1_labels = newvaldf[newvaldf.columns[187:188]].values\n",
        "y_test = test_1_labels.reshape(test_1_labels.shape[0])\n",
        "test_1_data = test_1_data.reshape((test_1_data.shape[0],1,test_1_data.shape[1]))\n",
        "test_1_data = test_1_data.astype(float)\n",
        "\n",
        "\n",
        "final_test_1_data = newtestdf[newtestdf.columns[:187]].values\n",
        "final_test_1_labels = newtestdf[newtestdf.columns[187:188]].values\n",
        "y_final_test = final_test_1_labels.reshape(final_test_1_labels.shape[0])\n",
        "final_test_1_data = final_test_1_data.reshape((final_test_1_data.shape[0],1,final_test_1_data.shape[1]))\n",
        "final_test_1_data = final_test_1_data.astype(float)\n",
        "\n",
        "X_train,X_test,X_final_test=standardize(train_1_data,test_1_data,final_test_1_data)"
      ],
      "metadata": {
        "id": "xP49goYBPOGY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98wlc3JCY0YW",
        "outputId": "69cd25df-394a-4c5d-e921-96bc8bdded15"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 1, 187)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTSjAHBdY2w1",
        "outputId": "845da055-08a1-4cbf-fa31-b7d8a80a1784"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000,)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "L2mv8PrRSrL8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the NumPy arrays to PyTorch tensors\n",
        "train_loaded_data = torch.from_numpy(X_train)\n",
        "train_loaded_labels = torch.from_numpy(y_train)\n",
        "\n",
        "test_loaded_data = torch.from_numpy(X_test)\n",
        "test_loaded_labels = torch.from_numpy(y_test)\n",
        "\n",
        "final_test_loaded_data = torch.from_numpy(X_final_test)\n",
        "final_test_loaded_labels = torch.from_numpy(y_final_test)"
      ],
      "metadata": {
        "id": "0Z-yh2NIQ484"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import Module\n",
        "from torch.nn import Conv2d\n",
        "from torch.nn import Linear\n",
        "from torch.nn import MaxPool2d\n",
        "from torch.nn import ReLU\n",
        "from torch.nn import LogSoftmax\n",
        "from torch import flatten\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "eR6oLmzhS0QY"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4AXl_QZS7Jk",
        "outputId": "0d9c35d6-3bf8-4305-e97b-3f9500e93623"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 1, 187)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Define the CNN model\n",
        "class SimpleCNN(nn.Module):\n",
        "  def __init__(self, num_classes=5):\n",
        "      super(SimpleCNN, self).__init__()\n",
        "\n",
        "      # Convolutional layers\n",
        "      self.conv1 = nn.Conv1d(1, 100, kernel_size=3, stride=1, padding=1)\n",
        "      self.relu1 = nn.ReLU()\n",
        "      self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "\n",
        "      self.conv2 = nn.Conv1d(100, 500, kernel_size=3, stride=1, padding=1)\n",
        "      self.relu2 = nn.ReLU()\n",
        "      self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "\n",
        "      self.conv3 = nn.Conv1d(500, 500, kernel_size=3, stride=1, padding=1)\n",
        "      self.relu3 = nn.ReLU()\n",
        "      self.pool3 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "\n",
        "\n",
        "      self.dropout1 = nn.Dropout2d(p=0.5)\n",
        "      self.dropout2 = nn.Dropout2d(p=0.5)\n",
        "      self.dropout3 = nn.Dropout2d(p=0.5)\n",
        "      # Fully connected layers\n",
        "      self.fc1 = nn.Linear(11500, 128)\n",
        "      self.relu4 = nn.ReLU()\n",
        "      self.fc2 = nn.Linear(128, num_classes)\n",
        "      self.outputactication = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = self.pool1(self.relu1(self.conv1(x)))\n",
        "      # x = self.dropout1(x)\n",
        "\n",
        "      # print(x.shape)\n",
        "      x = self.pool2(self.relu2(self.conv2(x)))\n",
        "      # x = self.dropout2(x)\n",
        "      x = self.pool3(self.relu3(self.conv3(x)))\n",
        "      # x = self.dropout3(x)\n",
        "      # print(x.shape)\n",
        "      x = x.view(-1, 11500)  # Reshape before fully connected layer\n",
        "      x = self.relu4(self.fc1(x))\n",
        "      x = self.fc2(x)\n",
        "      x = self.outputactication(x)\n",
        "      # print(x.shape)\n",
        "      return x"
      ],
      "metadata": {
        "id": "LSKt6IOOSwuy"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "8GsPplQbT5Rd"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 500  # Adjust as needed\n",
        "train_dataset = TensorDataset(train_loaded_data, train_loaded_labels)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_dataset = TensorDataset(test_loaded_data, test_loaded_labels)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "final_test_dataset = TensorDataset(final_test_loaded_data, final_test_loaded_labels)\n",
        "final_test_loader = DataLoader(final_test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "-xSLdfldUjiI"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getAccuracy(neuralmodel,loader):\n",
        "    neuralmodel.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs = inputs.float()\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = neuralmodel(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Calculate test accuracy\n",
        "    test_accuracy = correct / total\n",
        "    return test_accuracy,(f'{test_accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "L_cLjWWtUmGL"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plotdata=[]\n",
        "num_epochs = 101\n",
        "cnn_model = SimpleCNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "learning_rate = 0.01\n",
        "# cnn_model.train()\n",
        "# optimizer = optim.SGD(cnn_model.parameters(),lr=10)\n",
        "optimizer = optim.SGD(cnn_model.parameters(), lr=learning_rate,momentum=0.9)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "cnn_model.to(device)\n",
        "for epoch in range(num_epochs):\n",
        "    for inputs, labels in train_loader:\n",
        "        # print(inputs.shape)\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        inputs = inputs.float()\n",
        "        outputs = cnn_model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "    if (epoch) % 10 == 0:\n",
        "        # print(outputs.sum())\n",
        "        # print(loss.numpy())\n",
        "\n",
        "\n",
        "        train_val,trainacc=getAccuracy(cnn_model,train_loader)\n",
        "        test_val,testacc=getAccuracy(cnn_model,test_loader)\n",
        "        plotdata.append([epoch+1,train_val,test_val])\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "        print(\"Train Acc \",trainacc,\" Test Acc \",testacc)\n",
        "\n",
        "        cnn_model.train()\n",
        "print(\"Training complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZBO_uqZUrqJ",
        "outputId": "d5cb9973-c8a6-4d0d-9c65-713f3dbc816a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/101], Loss: 1.2330\n",
            "Train Acc  67.05%  Test Acc  52.27%\n",
            "Epoch [11/101], Loss: 1.0435\n",
            "Train Acc  80.87%  Test Acc  74.66%\n",
            "Epoch [21/101], Loss: 1.0248\n",
            "Train Acc  86.23%  Test Acc  86.42%\n",
            "Epoch [31/101], Loss: 0.9969\n",
            "Train Acc  88.55%  Test Acc  87.40%\n",
            "Epoch [41/101], Loss: 0.9839\n",
            "Train Acc  90.06%  Test Acc  87.92%\n",
            "Epoch [51/101], Loss: 0.9723\n",
            "Train Acc  91.11%  Test Acc  90.68%\n",
            "Epoch [61/101], Loss: 0.9634\n",
            "Train Acc  91.69%  Test Acc  89.54%\n",
            "Epoch [71/101], Loss: 0.9609\n",
            "Train Acc  92.19%  Test Acc  91.84%\n",
            "Epoch [81/101], Loss: 0.9673\n",
            "Train Acc  92.24%  Test Acc  89.96%\n",
            "Epoch [91/101], Loss: 0.9687\n",
            "Train Acc  92.60%  Test Acc  93.14%\n",
            "Epoch [101/101], Loss: 0.9483\n",
            "Train Acc  92.79%  Test Acc  91.24%\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plotdf = pd.DataFrame(columns=[\"Epoch\",\"Train Acc\",\"Test Acc\"])\n",
        "\n",
        "for dat in plotdata:\n",
        "  plotdf.loc[plotdf.shape[0]]=dat"
      ],
      "metadata": {
        "id": "JOfATjZkUvLC"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plotdf.to_csv(\"/content/gdrive/MyDrive/ECGData/PlotData/cnn_plotdata.csv\",index=False)"
      ],
      "metadata": {
        "id": "cb9k0ReN7YXT"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(cnn_model.state_dict(), \"/content/gdrive/MyDrive/ECGData/Models/CNN_model.pth\")"
      ],
      "metadata": {
        "id": "fCAKd_jQ7brl"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "total_labels=[]\n",
        "total_predicted=[]\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in final_test_loader:\n",
        "        inputs = inputs.float()\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = cnn_model(inputs)\n",
        "        total_labels = total_labels +labels.tolist()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        total_predicted = total_predicted+predicted.tolist()\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "# Calculate test accuracy\n",
        "test_accuracy = correct / total\n",
        "print(f'{test_accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrcdJFJx7eh-",
        "outputId": "4704cd27-d6a6-467f-a3e2-6213743062e6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "91.24%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
      ],
      "metadata": {
        "id": "VZJHbkuO7lkJ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true_np = np.array(total_labels)\n",
        "y_pred_np = np.array(total_predicted)\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(y_true_np, y_pred_np, average='weighted')\n",
        "recall = recall_score(y_true_np, y_pred_np, average='weighted')\n",
        "f1 = f1_score(y_true_np, y_pred_np, average='weighted')\n",
        "accuracy = accuracy_score(y_true_np, y_pred_np)\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEl7EOWu7gBm",
        "outputId": "068d5fa5-1e68-4ec5-e660-77474b67dd7e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.9528105599409815\n",
            "Recall: 0.91238808697241\n",
            "F1 Score: 0.9269991787381682\n",
            "Accuracy: 0.91238808697241\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_df = pd.DataFrame(columns=[\"Metric\",\"Value\"])\n",
        "metrics_df.loc[0]=[\"Accuracy\",accuracy]\n",
        "metrics_df.loc[1]=[\"Precision\",precision]\n",
        "metrics_df.loc[2]=[\"Recall\",recall]\n",
        "metrics_df.loc[3]=[\"F1 Score\",f1]\n",
        "metrics_df.to_csv(\"/content/gdrive/MyDrive/ECGData/Metrics/CNN_metrics.csv\",index=False)"
      ],
      "metadata": {
        "id": "u5wmRELC7hs2"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JYS8Kqj__u_y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}