{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lcp1TSlrKNpA",
        "outputId": "92c2e6f5-2647-4d89-b201-634b8e9684eb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "7cL4znvhLKVS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df=pd.read_csv('/content/gdrive/MyDrive/ECGData/mitbih_train.csv',header=None)\n",
        "test_df=pd.read_csv('/content/gdrive/MyDrive/ECGData/mitbih_test.csv',header=None)"
      ],
      "metadata": {
        "id": "viu3wXknKzVj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[187]=train_df[187].astype(int)\n",
        "distribution=train_df[187].value_counts()\n",
        "print(distribution)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tLXYuI2LFFy",
        "outputId": "3ee9fede-4a47-4940-b633-c7af78480dd1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    72471\n",
            "4     6431\n",
            "2     5788\n",
            "1     2223\n",
            "3      641\n",
            "Name: 187, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df[187]=test_df[187].astype(int)\n",
        "distribution=test_df[187].value_counts()\n",
        "print(distribution)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58LryzyRM3L6",
        "outputId": "9c9c34d1-1d98-494b-ef9d-394a5fa15976"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    18118\n",
            "4     1608\n",
            "2     1448\n",
            "1      556\n",
            "3      162\n",
            "Name: 187, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(distribution)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1DiWcrcLeJ8",
        "outputId": "5b02e0f7-cde6-451e-f526-5747339639bb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "count1=10000\n",
        "newtraindf=(train_df[train_df[187]==0]).sample(n=count1)\n",
        "for i in range(1,5):\n",
        "  df_i=train_df[train_df[187]==i]\n",
        "  df_x=resample(df_i,replace=True,n_samples=count1)\n",
        "  newtraindf=pd.concat([newtraindf,df_x])\n",
        "\n",
        "newtestdf=pd.DataFrame()\n",
        "newvaldf=pd.DataFrame()\n",
        "\n",
        "for i in range(0,5):\n",
        "  shuffled_df=test_df[test_df[187]==i].sample(frac=1, random_state=42)\n",
        "  split_index = len(shuffled_df) // 2\n",
        "  df_half1 = shuffled_df.iloc[:split_index, :]\n",
        "  df_half2 = shuffled_df.iloc[split_index:, :]\n",
        "  newtestdf=pd.concat([newtestdf,df_half1])\n",
        "  newvaldf=pd.concat([newvaldf,df_half1])"
      ],
      "metadata": {
        "id": "YmtXwrjNLk2I"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def standardize(train,test,final_test):\n",
        "\n",
        "    mean = np.mean(train, axis=0)\n",
        "    std = np.std(train, axis=0)+0.000001\n",
        "\n",
        "    X_train = (train - mean) / std\n",
        "    X_test = (test-mean)/std\n",
        "    X_final_test = (final_test-mean)/std\n",
        "    return X_train,X_test,X_final_test"
      ],
      "metadata": {
        "id": "67wN-BhLQZXG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Access the datasets in the HDF5 file\n",
        "train_1_data = newtraindf[newtraindf.columns[:187]].values\n",
        "train_1_labels = newtraindf[newtraindf.columns[187:188]].values\n",
        "y_train = train_1_labels.reshape(train_1_labels.shape[0])\n",
        "train_1_data = train_1_data.reshape((train_1_data.shape[0],1,train_1_data.shape[1]))\n",
        "train_1_data = train_1_data.astype(float)\n",
        "\n",
        "\n",
        "test_1_data = newvaldf[newvaldf.columns[:187]].values\n",
        "test_1_labels = newvaldf[newvaldf.columns[187:188]].values\n",
        "y_test = test_1_labels.reshape(test_1_labels.shape[0])\n",
        "test_1_data = test_1_data.reshape((test_1_data.shape[0],1,test_1_data.shape[1]))\n",
        "test_1_data = test_1_data.astype(float)\n",
        "\n",
        "\n",
        "final_test_1_data = newtestdf[newtestdf.columns[:187]].values\n",
        "final_test_1_labels = newtestdf[newtestdf.columns[187:188]].values\n",
        "y_final_test = final_test_1_labels.reshape(final_test_1_labels.shape[0])\n",
        "final_test_1_data = final_test_1_data.reshape((final_test_1_data.shape[0],1,final_test_1_data.shape[1]))\n",
        "final_test_1_data = final_test_1_data.astype(float)\n",
        "\n",
        "X_train,X_test,X_final_test=standardize(train_1_data,test_1_data,final_test_1_data)"
      ],
      "metadata": {
        "id": "xP49goYBPOGY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98wlc3JCY0YW",
        "outputId": "cbb7711d-9e60-4087-850d-dcfd20d6f8ce"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 1, 187)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTSjAHBdY2w1",
        "outputId": "470baea0-bb99-4df4-d4da-6543705f7e07"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000,)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "L2mv8PrRSrL8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the NumPy arrays to PyTorch tensors\n",
        "train_loaded_data = torch.from_numpy(X_train)\n",
        "train_loaded_labels = torch.from_numpy(y_train)\n",
        "\n",
        "test_loaded_data = torch.from_numpy(X_test)\n",
        "test_loaded_labels = torch.from_numpy(y_test)\n",
        "\n",
        "final_test_loaded_data = torch.from_numpy(X_final_test)\n",
        "final_test_loaded_labels = torch.from_numpy(y_final_test)"
      ],
      "metadata": {
        "id": "0Z-yh2NIQ484"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import Module\n",
        "from torch.nn import Conv2d\n",
        "from torch.nn import Linear\n",
        "from torch.nn import MaxPool2d\n",
        "from torch.nn import ReLU\n",
        "from torch.nn import LogSoftmax\n",
        "from torch import flatten\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "eR6oLmzhS0QY"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4AXl_QZS7Jk",
        "outputId": "2dbcef19-c35e-458c-9269-a825a9ce7ea3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 1, 187)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size=187, hidden_size=64, num_layers=2, num_classes=5):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # LSTM layer\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Set initial hidden and cell states\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "\n",
        "        # Forward pass through LSTM layer\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "\n",
        "        # Take the output from the last time step\n",
        "        out = out[:, -1, :]\n",
        "\n",
        "        # Forward pass through the fully connected layer\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "LSKt6IOOSwuy"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "8GsPplQbT5Rd"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 500  # Adjust as needed\n",
        "train_dataset = TensorDataset(train_loaded_data, train_loaded_labels)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_dataset = TensorDataset(test_loaded_data, test_loaded_labels)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "final_test_dataset = TensorDataset(final_test_loaded_data, final_test_loaded_labels)\n",
        "final_test_loader = DataLoader(final_test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "-xSLdfldUjiI"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getAccuracy(neuralmodel,loader):\n",
        "    neuralmodel.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs = inputs.float()\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = neuralmodel(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Calculate test accuracy\n",
        "    test_accuracy = correct / total\n",
        "    return test_accuracy,(f'{test_accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "L_cLjWWtUmGL"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plotdata=[]\n",
        "num_epochs = 101\n",
        "cnn_model = LSTMModel()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "learning_rate = 0.01\n",
        "# cnn_model.train()\n",
        "# optimizer = optim.SGD(cnn_model.parameters(),lr=10)\n",
        "optimizer = optim.SGD(cnn_model.parameters(), lr=learning_rate,momentum=0.9)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "cnn_model.to(device)\n",
        "for epoch in range(num_epochs):\n",
        "    for inputs, labels in train_loader:\n",
        "        # print(inputs.shape)\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        inputs = inputs.float()\n",
        "        outputs = cnn_model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "    if (epoch) % 10 == 0:\n",
        "        # print(outputs.sum())\n",
        "        # print(loss.numpy())\n",
        "\n",
        "\n",
        "        train_val,trainacc=getAccuracy(cnn_model,train_loader)\n",
        "        test_val,testacc=getAccuracy(cnn_model,test_loader)\n",
        "        plotdata.append([epoch+1,train_val,test_val])\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "        print(\"Train Acc \",trainacc,\" Test Acc \",testacc)\n",
        "\n",
        "        cnn_model.train()\n",
        "print(\"Training complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZBO_uqZUrqJ",
        "outputId": "c642f535-454e-44ff-b27f-8008111b1701"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/101], Loss: 1.5864\n",
            "Train Acc  37.57%  Test Acc  12.95%\n",
            "Epoch [11/101], Loss: 0.5566\n",
            "Train Acc  78.86%  Test Acc  59.03%\n",
            "Epoch [21/101], Loss: 0.3156\n",
            "Train Acc  88.87%  Test Acc  84.57%\n",
            "Epoch [31/101], Loss: 0.2009\n",
            "Train Acc  92.34%  Test Acc  87.84%\n",
            "Epoch [41/101], Loss: 0.1481\n",
            "Train Acc  94.88%  Test Acc  89.55%\n",
            "Epoch [51/101], Loss: 0.1321\n",
            "Train Acc  96.28%  Test Acc  90.91%\n",
            "Epoch [61/101], Loss: 0.0791\n",
            "Train Acc  97.13%  Test Acc  92.23%\n",
            "Epoch [71/101], Loss: 0.1032\n",
            "Train Acc  97.84%  Test Acc  92.79%\n",
            "Epoch [81/101], Loss: 0.0460\n",
            "Train Acc  98.36%  Test Acc  92.97%\n",
            "Epoch [91/101], Loss: 0.0594\n",
            "Train Acc  98.69%  Test Acc  93.34%\n",
            "Epoch [101/101], Loss: 0.0441\n",
            "Train Acc  99.06%  Test Acc  93.86%\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plotdf = pd.DataFrame(columns=[\"Epoch\",\"Train Acc\",\"Test Acc\"])\n",
        "\n",
        "for dat in plotdata:\n",
        "  plotdf.loc[plotdf.shape[0]]=dat"
      ],
      "metadata": {
        "id": "JOfATjZkUvLC"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plotdf.to_csv(\"/content/gdrive/MyDrive/ECGData/PlotData/lstm_plotdata.csv\",index=False)"
      ],
      "metadata": {
        "id": "-9jKm5uJ8JNx"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(cnn_model.state_dict(), \"/content/gdrive/MyDrive/ECGData/Models/LSTM_model.pth\")"
      ],
      "metadata": {
        "id": "trp49G0N8MhZ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "total_labels=[]\n",
        "total_predicted=[]\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in final_test_loader:\n",
        "        inputs = inputs.float()\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = cnn_model(inputs)\n",
        "        total_labels = total_labels +labels.tolist()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        total_predicted = total_predicted+predicted.tolist()\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "# Calculate test accuracy\n",
        "test_accuracy = correct / total\n",
        "print(f'{test_accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UnAItlY8Pmg",
        "outputId": "5fda15c3-5bd8-4b52-98af-6363f8c06ce3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "93.86%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
      ],
      "metadata": {
        "id": "U4XR4yU28ROY"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true_np = np.array(total_labels)\n",
        "y_pred_np = np.array(total_predicted)\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(y_true_np, y_pred_np, average='weighted')\n",
        "recall = recall_score(y_true_np, y_pred_np, average='weighted')\n",
        "f1 = f1_score(y_true_np, y_pred_np, average='weighted')\n",
        "accuracy = accuracy_score(y_true_np, y_pred_np)\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eXUmPgQ8SeL",
        "outputId": "f5565a3a-578e-4792-8aac-0e1f8bfd4440"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.9573660759022167\n",
            "Recall: 0.938607710579207\n",
            "F1 Score: 0.945263186096288\n",
            "Accuracy: 0.938607710579207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_df = pd.DataFrame(columns=[\"Metric\",\"Value\"])\n",
        "metrics_df.loc[0]=[\"Accuracy\",accuracy]\n",
        "metrics_df.loc[1]=[\"Precision\",precision]\n",
        "metrics_df.loc[2]=[\"Recall\",recall]\n",
        "metrics_df.loc[3]=[\"F1 Score\",f1]\n",
        "metrics_df.to_csv(\"/content/gdrive/MyDrive/ECGData/Metrics/LSTM_metrics.csv\",index=False)"
      ],
      "metadata": {
        "id": "aN_bZM5n8T-b"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hPqAcLv3_41o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}